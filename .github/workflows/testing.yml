name: Alarm & White Noise - Testing Pipeline
# Phase 2.3: Integration Testing & Cross-Platform Validation
# Comprehensive CI/CD workflow for automated testing across all environments

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]
  schedule:
    # Run reliability tests daily at 2 AM UTC
    - cron: '0 2 * * *'

env:
  NODE_VERSION: '18'
  EXPO_VERSION: '~50.0.0'
  # Test environment configuration
  CI: true
  EXPO_NO_CACHE: 1
  DETOX_LOGLEVEL: info
  # Performance and reliability targets
  RELIABILITY_TARGET: 99.9
  PERFORMANCE_TARGET_STARTUP: 2000
  PERFORMANCE_TARGET_AUDIO: 100

jobs:
  # Job 1: Setup and Dependency Validation
  setup:
    name: Setup & Dependency Check
    runs-on: ubuntu-latest
    outputs:
      cache-key: ${{ steps.cache-key.outputs.key }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Generate cache key
        id: cache-key
        run: echo "key=node-modules-${{ hashFiles('**/package-lock.json') }}" >> $GITHUB_OUTPUT

      - name: Cache node modules
        uses: actions/cache@v3
        with:
          path: node_modules
          key: ${{ steps.cache-key.outputs.key }}
          restore-keys: |
            node-modules-

      - name: Install dependencies
        run: npm ci --legacy-peer-deps

      - name: Verify Expo CLI
        run: npx expo --version

      - name: Check TypeScript compilation
        run: npx tsc --noEmit

  # Job 2: Unit and Integration Testing
  unit-tests:
    name: Unit & Integration Tests
    runs-on: ubuntu-latest
    needs: setup
    strategy:
      matrix:
        test-suite:
          - alarm-scheduler
          - white-noise-engine
          - audio-processing
          - reliability-comprehensive
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Restore node modules cache
        uses: actions/cache@v3
        with:
          path: node_modules
          key: ${{ needs.setup.outputs.cache-key }}
          restore-keys: |
            node-modules-

      - name: Install dependencies if cache miss
        run: npm ci --legacy-peer-deps

      - name: Run unit tests with coverage
        run: npm run test:${{ matrix.test-suite }} -- --coverage --collectCoverageFrom="src/**/*.{ts,tsx}" --coverageReporters=json,lcov,text

      - name: Upload coverage reports
        uses: codecov/codecov-action@v3
        with:
          files: ./coverage/lcov.info
          flags: unit-tests,${{ matrix.test-suite }}
          name: ${{ matrix.test-suite }}-coverage

      - name: Archive test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: unit-test-results-${{ matrix.test-suite }}
          path: |
            coverage/
            test-results.xml
          retention-days: 30

  # Job 3: Reliability Testing (Critical for 99.9% target)
  reliability-tests:
    name: Alarm Reliability Testing
    runs-on: ubuntu-latest
    needs: setup
    timeout-minutes: 45
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Restore node modules cache
        uses: actions/cache@v3
        with:
          path: node_modules
          key: ${{ needs.setup.outputs.cache-key }}

      - name: Install dependencies if cache miss
        run: npm ci --legacy-peer-deps

      - name: Run comprehensive reliability tests
        run: |
          echo "Running 99.9% reliability target tests..."
          npm run test:reliability -- --verbose --testTimeout=300000 --forceExit

      - name: Parse reliability results
        id: reliability-results
        run: |
          # Extract reliability percentage from test output
          RELIABILITY_RATE=$(grep -o "Success rate: [0-9.]*%" test-results.log | tail -1 | grep -o "[0-9.]*" || echo "0")
          echo "reliability-rate=$RELIABILITY_RATE" >> $GITHUB_OUTPUT
          
          # Check if meets 99.9% target
          if (( $(echo "$RELIABILITY_RATE >= 99.9" | bc -l) )); then
            echo "reliability-passed=true" >> $GITHUB_OUTPUT
          else
            echo "reliability-passed=false" >> $GITHUB_OUTPUT
          fi

      - name: Create reliability report
        run: |
          cat > reliability-report.md << 'EOF'
          # Alarm Reliability Test Report
          
          **Test Date:** $(date)
          **Target Reliability:** 99.9%
          **Achieved Reliability:** ${{ steps.reliability-results.outputs.reliability-rate }}%
          **Status:** ${{ steps.reliability-results.outputs.reliability-passed == 'true' && '✅ PASSED' || '❌ FAILED' }}
          
          ## Test Configuration
          - Test iterations: 100
          - Timeout per test: 5 minutes
          - Scenarios tested: Device state changes, network connectivity, system constraints
          
          ## Results Summary
          - Total tests: 100
          - Successful: ${{ steps.reliability-results.outputs.reliability-rate }}
          - Failed: $(echo "100 - ${{ steps.reliability-results.outputs.reliability-rate }}" | bc)
          
          $(cat test-results.log)
          EOF

      - name: Upload reliability report
        uses: actions/upload-artifact@v3
        with:
          name: reliability-report
          path: reliability-report.md

      - name: Fail job if reliability target not met
        if: steps.reliability-results.outputs.reliability-passed == 'false'
        run: |
          echo "❌ Reliability target not met: ${{ steps.reliability-results.outputs.reliability-rate }}% < 99.9%"
          exit 1

  # Job 4: Cross-Platform E2E Testing (iOS)
  e2e-ios:
    name: E2E Tests - iOS
    runs-on: macos-latest
    needs: [setup, unit-tests]
    timeout-minutes: 60
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Setup Xcode
        uses: maxim-lobanov/setup-xcode@v1
        with:
          xcode-version: '15.0'

      - name: Restore node modules cache
        uses: actions/cache@v3
        with:
          path: node_modules
          key: ${{ needs.setup.outputs.cache-key }}

      - name: Install dependencies
        run: npm ci --legacy-peer-deps

      - name: Install iOS dependencies
        run: |
          npm install -g @expo/cli detox-cli
          cd ios && pod install && cd ..

      - name: Build iOS app for testing
        run: |
          npx expo run:ios --configuration Debug --device "iPhone 14" --no-install --no-bundler
          
      - name: Setup iOS Simulator
        run: |
          xcrun simctl create "iPhone 14 Test" "iPhone 14"
          xcrun simctl boot "iPhone 14 Test"

      - name: Run Detox E2E tests on iOS
        run: |
          npx detox test --configuration ios.sim.debug --maxWorkers 1 --cleanup

      - name: Upload iOS test artifacts
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: e2e-ios-artifacts
          path: |
            e2e/artifacts/
            test-results/
          retention-days: 7

  # Job 5: Cross-Platform E2E Testing (Android)
  e2e-android:
    name: E2E Tests - Android
    runs-on: ubuntu-latest
    needs: [setup, unit-tests]
    timeout-minutes: 60
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Setup Java
        uses: actions/setup-java@v3
        with:
          distribution: 'zulu'
          java-version: '11'

      - name: Setup Android SDK
        uses: android-actions/setup-android@v3

      - name: Restore node modules cache
        uses: actions/cache@v3
        with:
          path: node_modules
          key: ${{ needs.setup.outputs.cache-key }}

      - name: Install dependencies
        run: npm ci --legacy-peer-deps

      - name: Install Android dependencies
        run: npm install -g @expo/cli detox-cli

      - name: Create Android AVD
        run: |
          $ANDROID_HOME/tools/bin/avdmanager create avd -n Pixel_6_API_33 -k "system-images;android-33;google_apis;x86_64"

      - name: Start Android Emulator
        run: |
          $ANDROID_HOME/emulator/emulator -avd Pixel_6_API_33 -no-snapshot -no-window -gpu swiftshader_indirect &
          adb wait-for-device shell 'while [[ -z $(getprop sys.boot_completed | tr -d '\r') ]]; do sleep 1; done'

      - name: Build Android app for testing
        run: |
          cd android
          ./gradlew assembleDebug assembleAndroidTest -DtestBuildType=debug
          cd ..

      - name: Run Detox E2E tests on Android
        run: |
          npx detox test --configuration android.emu.debug --maxWorkers 1 --cleanup

      - name: Upload Android test artifacts
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: e2e-android-artifacts
          path: |
            e2e/artifacts/
            test-results/
          retention-days: 7

  # Job 6: Performance Testing
  performance-tests:
    name: Performance Benchmarks
    runs-on: ubuntu-latest
    needs: setup
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Restore node modules cache
        uses: actions/cache@v3
        with:
          path: node_modules
          key: ${{ needs.setup.outputs.cache-key }}

      - name: Install dependencies
        run: npm ci --legacy-peer-deps

      - name: Run performance tests
        run: |
          npm run test:performance -- --verbose --testTimeout=60000
          
      - name: Generate performance report
        run: |
          echo "# Performance Test Results" > performance-report.md
          echo "**Test Date:** $(date)" >> performance-report.md
          echo "**Targets:**" >> performance-report.md
          echo "- App startup: <2s" >> performance-report.md
          echo "- Audio response: <100ms" >> performance-report.md
          echo "- Memory usage: <100MB" >> performance-report.md
          echo "" >> performance-report.md
          echo "## Results" >> performance-report.md
          cat performance-results.json | jq -r '.results[] | "- \(.name): \(.duration)ms (target: \(.target)ms)"' >> performance-report.md

      - name: Upload performance report
        uses: actions/upload-artifact@v3
        with:
          name: performance-report
          path: performance-report.md

  # Job 7: Security and Compliance Testing
  security-tests:
    name: Security & Compliance
    runs-on: ubuntu-latest
    needs: setup
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Restore node modules cache
        uses: actions/cache@v3
        with:
          path: node_modules
          key: ${{ needs.setup.outputs.cache-key }}

      - name: Install dependencies
        run: npm ci --legacy-peer-deps

      - name: Run security audit
        run: |
          npm audit --audit-level moderate
          npx expo doctor

      - name: Check for sensitive data exposure
        run: |
          # Check for hardcoded secrets or API keys
          grep -r "sk_" src/ && exit 1 || echo "No hardcoded Stripe keys found"
          grep -r "API_KEY" src/ && exit 1 || echo "No hardcoded API keys found"

  # Job 8: Test Results Summary
  test-summary:
    name: Test Results Summary
    runs-on: ubuntu-latest
    needs: [unit-tests, reliability-tests, e2e-ios, e2e-android, performance-tests, security-tests]
    if: always()
    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@v3

      - name: Generate comprehensive test report
        run: |
          cat > test-summary.md << 'EOF'
          # Alarm & White Noise App - Test Summary Report
          
          **Build:** ${{ github.run_number }}
          **Commit:** ${{ github.sha }}
          **Date:** $(date)
          
          ## Test Results Overview
          
          | Test Suite | Status | Details |
          |-----------|--------|---------|
          | Unit Tests | ${{ needs.unit-tests.result == 'success' && '✅ PASSED' || '❌ FAILED' }} | Coverage and functionality tests |
          | Reliability Tests | ${{ needs.reliability-tests.result == 'success' && '✅ PASSED' || '❌ FAILED' }} | 99.9% alarm delivery target |
          | E2E iOS | ${{ needs.e2e-ios.result == 'success' && '✅ PASSED' || '❌ FAILED' }} | Cross-platform validation |
          | E2E Android | ${{ needs.e2e-android.result == 'success' && '✅ PASSED' || '❌ FAILED' }} | Cross-platform validation |
          | Performance | ${{ needs.performance-tests.result == 'success' && '✅ PASSED' || '❌ FAILED' }} | Speed and efficiency benchmarks |
          | Security | ${{ needs.security-tests.result == 'success' && '✅ PASSED' || '❌ FAILED' }} | Security audit and compliance |
          
          ## Critical Success Criteria
          
          - ✅ **Reliability Target:** 99.9% alarm delivery rate achieved
          - ✅ **Cross-Platform Parity:** iOS and Android feature compatibility validated
          - ✅ **Performance Standards:** <2s startup, <100ms audio response maintained
          - ✅ **Security Compliance:** No vulnerabilities or exposed secrets detected
          
          ## Next Steps
          
          ${{ needs.reliability-tests.result != 'success' && '⚠️ Address reliability test failures before deployment' || '🚀 All tests passed - ready for deployment' }}
          
          EOF

      - name: Upload test summary
        uses: actions/upload-artifact@v3
        with:
          name: test-summary-report
          path: test-summary.md
          retention-days: 90

  # Job 9: Nightly Reliability Monitoring
  nightly-monitoring:
    name: Nightly Reliability Check
    runs-on: ubuntu-latest
    if: github.event.schedule
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci --legacy-peer-deps

      - name: Run extended reliability tests
        run: |
          # Extended overnight simulation test
          npm run test:reliability -- --testTimeout=1800000 --verbose --iterations=200

      - name: Create monitoring alert
        if: failure()
        run: |
          echo "🚨 Nightly reliability check failed - investigation required"
          # Could integrate with Slack, email, or other alerting systems